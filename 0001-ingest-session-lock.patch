diff --git a/src/ledger/__init__.py b/src/ledger/__init__.py
index 6f9d3c2..f2c2a11 100644
--- a/src/ledger/__init__.py
+++ b/src/ledger/__init__.py
@@ -1 +1 @@
-__all__ = ["cas", "manifest", "replay", "verify"]
+__all__ = ["cas", "manifest", "replay", "verify", "locks"]

diff --git a/src/ledger/locks.py b/src/ledger/locks.py
new file mode 100644
index 0000000..0c3f8a1
--- /dev/null
+++ b/src/ledger/locks.py
@@ -0,0 +1,152 @@
+from __future__ import annotations
+
+import os
+from contextlib import contextmanager
+from pathlib import Path
+from typing import Iterator
+
+
+def _truthy(v: str) -> bool:
+    s = v.strip().lower()
+    return s in ("1", "true", "yes", "y", "on")
+
+
+def _falsey(v: str) -> bool:
+    s = v.strip().lower()
+    return s in ("0", "false", "no", "n", "off")
+
+
+def ingest_session_lock_path(repo_root: Path) -> Path:
+    """
+    Repo-wide ingest-session lock path.
+
+    Stored under ledger/ so the lock is per-repo/worktree (not per cwd).
+    Recommended to ignore in git: ledger/.locks/
+    """
+    return Path(repo_root) / "ledger" / ".locks" / "ingest.lock"
+
+
+@contextmanager
+def file_lock(lock_path: Path) -> Iterator[None]:
+    """
+    Cross-process exclusive advisory lock.
+
+    POSIX: fcntl.flock
+    Windows: msvcrt.locking (1-byte range lock)
+
+    Lock lifetime is tied to the open FD; crashes release locks.
+    """
+    lock_path = Path(lock_path)
+    lock_path.parent.mkdir(parents=True, exist_ok=True)
+
+    f = lock_path.open("a+b")
+    try:
+        # Ensure at least 1 byte exists for Windows range locks.
+        try:
+            f.seek(0, os.SEEK_END)
+            if f.tell() == 0:
+                f.write(b"\0")
+                f.flush()
+        except Exception:
+            pass
+
+        if os.name == "posix":
+            import fcntl  # type: ignore
+
+            fcntl.flock(f.fileno(), fcntl.LOCK_EX)
+            try:
+                yield
+            finally:
+                try:
+                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)
+                except Exception:
+                    pass
+        else:
+            import msvcrt  # type: ignore
+
+            f.seek(0)
+            msvcrt.locking(f.fileno(), msvcrt.LK_LOCK, 1)
+            try:
+                yield
+            finally:
+                try:
+                    f.seek(0)
+                    msvcrt.locking(f.fileno(), msvcrt.LK_UNLCK, 1)
+                except Exception:
+                    pass
+    finally:
+        try:
+            f.close()
+        except Exception:
+            pass
+
+
+@contextmanager
+def ingest_session_lock(repo_root: Path) -> Iterator[None]:
+    """Convenience wrapper for the repo-wide ingest-session lock."""
+    with file_lock(ingest_session_lock_path(repo_root)):
+        yield
+
+
+def ingest_session_lock_enabled(*, cli_no_session_lock: bool = False) -> bool:
+    """
+    Maximal safety default: ON.
+
+    Controls:
+      - CLI: --no-session-lock disables
+      - Env: LEDGER_INGEST_SESSION_LOCK overrides (true/false)
+
+    Unknown env values => default ON.
+    """
+    if cli_no_session_lock:
+        return False
+
+    v = os.environ.get("LEDGER_INGEST_SESSION_LOCK")
+    if v is None:
+        return True
+
+    if _truthy(v):
+        return True
+    if _falsey(v):
+        return False
+
+    return True

diff --git a/src/ledger/cli.py b/src/ledger/cli.py
index 3a9b1df..7bf61b3 100644
--- a/src/ledger/cli.py
+++ b/src/ledger/cli.py
@@ -1,12 +1,13 @@
 from __future__ import annotations
 
 import argparse
 import json
 from pathlib import Path
 from typing import Any, Dict
 
 from .cas import CasPaths, sha256_file, sha256_bytes, store_blob
 from .manifest import Node, Transform, write_node_manifest
 from .replay import replay_node
 from .verify import verify_node, verify_reachable
+from .locks import ingest_session_lock, ingest_session_lock_enabled
 
 def repo_root_from_cwd() -> Path:
     # Simple heuristic: walk up until we find 'ledger/' directory.
     p = Path.cwd().resolve()
@@ -35,52 +36,74 @@ def cmd_hash(args: argparse.Namespace) -> int:
     print(sha256_file(p))
     return 0
 
 def cmd_ingest(args: argparse.Namespace) -> int:
     repo_root = repo_root_from_cwd()
     src = Path(args.path)
     if not src.exists():
         raise SystemExit(f"no such file: {src}")
-
-    artifact_id = sha256_file(src)
-    cas = CasPaths.from_repo_root(repo_root)
-    store_blob(src, cas, artifact_id)
-
-    # Transform digest: by default hash the provided transform string (stable identifier),
-    # OR if a file path is provided via --transform-file, hash that file's bytes.
-    if args.transform_file:
-        tf = Path(args.transform_file)
-        if not tf.exists():
-            raise SystemExit(f"no such transform file: {tf}")
-        transform_digest = sha256_file(tf)
-        # Store transform definition in the CAS so it can be replayed by digest.
-        store_blob(tf, cas, transform_digest)
-        transform_name = args.transform or tf.name
-    else:
-        transform_name = args.transform or "unspecified"
-        transform_digest = sha256_bytes(transform_name.encode("utf-8"))
-
-    params: Dict[str, Any] = {}
-    if args.params_json:
-        params = json.loads(args.params_json)
-        if not isinstance(params, dict):
-            raise SystemExit("--params-json must decode to a JSON object")
-
-    node = Node(
-        id=artifact_id,
-        parents=args.parent or [],
-        transform=Transform(
-            name=transform_name,
-            digest=transform_digest,
-            params=params,
-            runner=args.runner,
-            env_digest=args.env_digest,
-        ),
-        meta={"note": args.note} if args.note else None,
-    )
-    write_node_manifest(repo_root, node)
-
-    print(artifact_id)
-    return 0
+
+    def _do_ingest() -> str:
+        artifact_id = sha256_file(src)
+        cas = CasPaths.from_repo_root(repo_root)
+        store_blob(src, cas, artifact_id)
+
+        # Transform digest: by default hash the provided transform string (stable identifier),
+        # OR if a file path is provided via --transform-file, hash that file's bytes.
+        if args.transform_file:
+            tf = Path(args.transform_file)
+            if not tf.exists():
+                raise SystemExit(f"no such transform file: {tf}")
+            transform_digest = sha256_file(tf)
+            # Store transform definition in the CAS so it can be replayed by digest.
+            store_blob(tf, cas, transform_digest)
+            transform_name = args.transform or tf.name
+        else:
+            transform_name = args.transform or "unspecified"
+            transform_digest = sha256_bytes(transform_name.encode("utf-8"))
+
+        params: Dict[str, Any] = {}
+        if args.params_json:
+            params = json.loads(args.params_json)
+            if not isinstance(params, dict):
+                raise SystemExit("--params-json must decode to a JSON object")
+
+        node = Node(
+            id=artifact_id,
+            parents=args.parent or [],
+            transform=Transform(
+                name=transform_name,
+                digest=transform_digest,
+                params=params,
+                runner=args.runner,
+                env_digest=args.env_digest,
+            ),
+            meta={"note": args.note} if args.note else None,
+        )
+        write_node_manifest(repo_root, node)
+        return artifact_id
+
+    if ingest_session_lock_enabled(cli_no_session_lock=bool(getattr(args, "no_session_lock", False))):
+        with ingest_session_lock(repo_root):
+            artifact_id = _do_ingest()
+    else:
+        artifact_id = _do_ingest()
+
+    print(artifact_id)
+    return 0
@@ -125,6 +148,9 @@ def build_parser() -> argparse.ArgumentParser:
     )
     p_ing.add_argument("--env-digest", help="sha256 of the execution environment description (lockfile/nix flake/container recipe).")
     p_ing.add_argument("--params-json", help="JSON object of semantic params (canonical).")
     p_ing.add_argument("--note", help="Non-semantic note.")
+    p_ing.add_argument(
+        "--no-session-lock", action="store_true", help="Disable repo-wide ingest-session lock (not recommended)."
+    )
     p_ing.set_defaults(fn=cmd_ingest)

diff --git a/tests/test_ingest_session_lock.py b/tests/test_ingest_session_lock.py
new file mode 100644
index 0000000..3a7cc2b
--- /dev/null
+++ b/tests/test_ingest_session_lock.py
@@ -0,0 +1,103 @@
+from __future__ import annotations
+
+import multiprocessing as mp
+import tempfile
+from pathlib import Path
+
+from ledger.locks import ingest_session_lock, ingest_session_lock_path
+
+
+def _init_repo(root: Path) -> None:
+    (root / "ledger").mkdir(parents=True, exist_ok=True)
+
+
+def _holder(repo: str, ready, ctrl) -> None:
+    repo_root = Path(repo)
+    with ingest_session_lock(repo_root):
+        ready.send("LOCKED")
+        msg = ctrl.recv()
+        assert msg == "RELEASE"
+
+
+def _waiter(repo: str, out) -> None:
+    repo_root = Path(repo)
+    with ingest_session_lock(repo_root):
+        out.send("ACQUIRED")
+
+
+def test_ingest_session_lock_blocks_other_processes() -> None:
+    ctx = mp.get_context("spawn")
+    with tempfile.TemporaryDirectory() as td:
+        repo_root = Path(td)
+        _init_repo(repo_root)
+
+        lp = ingest_session_lock_path(repo_root)
+        assert str(lp).endswith("ledger/.locks/ingest.lock")
+
+        ready_parent, ready_child = ctx.Pipe()
+        ctrl_parent, ctrl_child = ctx.Pipe()
+        out_parent, out_child = ctx.Pipe()
+
+        p1 = ctx.Process(target=_holder, args=(str(repo_root), ready_child, ctrl_child))
+        p1.start()
+        assert ready_parent.recv() == "LOCKED"
+
+        p2 = ctx.Process(target=_waiter, args=(str(repo_root), out_child))
+        p2.start()
+
+        # While p1 holds the lock, p2 must not acquire.
+        assert out_parent.poll(0.25) is False
+
+        # Release and ensure p2 acquires.
+        ctrl_parent.send("RELEASE")
+        assert out_parent.poll(2.0) is True
+        assert out_parent.recv() == "ACQUIRED"
+
+        p2.join(timeout=5)
+        p1.join(timeout=5)
+        assert p1.exitcode == 0
+        assert p2.exitcode == 0
